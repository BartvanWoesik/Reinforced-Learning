{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import tensorflow\r\n",
    "import gym\r\n",
    "import random\r\n",
    "import atari_py\r\n",
    "import numpy as np\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from rl.agents import DQNAgent\r\n",
    "from rl.memory import SequentialMemory\r\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "from gym import Env\r\n",
    "from gym.spaces import Discrete, Box\r\n",
    "import random\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def norm_fun( x): \r\n",
    "    \r\n",
    "    high    = x[0]\r\n",
    "    low     = x[0]\r\n",
    "    new_x = []\r\n",
    "\r\n",
    "    for n in range(0, len(x)):\r\n",
    "        if ( x[n] > high):\r\n",
    "            high = x[n]\r\n",
    "        if ( x[n] < low):\r\n",
    "            low = x[n]\r\n",
    "                \r\n",
    "    for n in range(0, len(x)):\r\n",
    "        new_x.append((x[n] -low) - (high - low))\r\n",
    "\r\n",
    "    return new_x\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "nsdq    = pd.read_csv(\"Nsdq.csv\")\r\n",
    "spy     = pd.read_csv(\"Spy.csv\")\r\n",
    "combi   = pd.merge(nsdq, spy, on = 'Date')\r\n",
    "combi[\"dif_x\"] = combi[\"Open_x\"] - combi[\"Close_x\"]\r\n",
    "combi[\"dif_y\"] = combi[\"Open_y\"] - combi[\"Close_y\"]\r\n",
    "\r\n",
    "combi = combi.dropna()\r\n",
    "\r\n",
    "tot_labels    = []\r\n",
    "nsdq_train   = []\r\n",
    "spy_train = []\r\n",
    "\r\n",
    "sum_ = 0 \r\n",
    "dif = []\r\n",
    "\r\n",
    "for x in range (1, len(combi)):\r\n",
    "            \r\n",
    "    if(combi.iloc[x][\"Open_x\"] > combi.iloc[x][\"Close_x\"] ):\r\n",
    "        tot_labels.append([1])\r\n",
    "        sum_ = sum_ +1\r\n",
    "        dif.append(combi.iloc[x][\"Open_x\"] - combi.iloc[x][\"Close_x\"] )\r\n",
    "    else:\r\n",
    "        tot_labels.append([0]) \r\n",
    "        dif.append(combi.iloc[x][\"Open_x\"] - combi.iloc[x][\"Close_x\"] )\r\n",
    "        sum_ = sum_ -1\r\n",
    "    temp_list_x =norm_fun( [combi.iloc[x-1][\"Open_x\"], combi.iloc[x-1][\"Close_x\"], \r\n",
    "                                    combi.iloc[x-1][\"High_x\"], combi.iloc[x-1][\"Low_x\"], combi.iloc[x][\"Open_x\"]])\r\n",
    "    temp_list_y = norm_fun([combi.iloc[x-1][\"Open_y\"], combi.iloc[x-1][\"Close_y\"], \r\n",
    "                                    combi.iloc[x-1][\"High_y\"], combi.iloc[x-1][\"Low_y\"]] )\r\n",
    "\r\n",
    "            \r\n",
    "    nsdq_train.append( temp_list_x )\r\n",
    "    spy_train.append( temp_list_y )\r\n",
    "\r\n",
    "        \r\n",
    "nsdq_train = tf.keras.utils.normalize(nsdq_train, axis =1)\r\n",
    "spy_train = tf.keras.utils.normalize(spy_train, axis=1)\r\n",
    "\r\n",
    "tot_train = np.concatenate((nsdq_train,spy_train), axis = 1)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "tot_labels = np.array(tot_labels)\r\n",
    "encoder = LabelEncoder()\r\n",
    "encoder.fit(tot_labels)\r\n",
    "encoded_Y = encoder.transform(tot_labels)\r\n",
    "\r\n",
    "\r\n",
    "print(dif)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-23.75, 2.25, 13.0, -2.25, 48.5, 7.0, 8.5, 46.0, 81.75, -81.5, -8.75, -82.25, -10.25, -32.75, 13.75, 7.75, -12.25, -2.75, 16.75, -37.5, 20.5, 87.75, -97.25, 20.25, 12.5, 74.5, -20.0, 107.0, -32.0, -34.5, -55.5, 79.0, 1.0, -49.25, -22.0, -16.25, -3.25, -2.75, -72.75, 41.25, 60.25, 88.0, 21.75, 35.25, 161.0, 36.5, -8.75, -40.5, 133.0, -76.0, 114.25, -17.75, 8.0, 0.5, -121.25, 60.75, -36.75, 68.25, -3.5, -128.0, -28.25, 94.5, 14.5, 14.0, 124.5, 63.0, 14.25, -12.75, 1.75, -43.0, -71.25, -107.0, 53.25, -4.75, -59.5, 48.0, -52.0, -29.75, 13.0, 24.0, -138.5, 5.25, 6.5, 0.5, 21.0, 30.5, -23.5, 10.25, -65.5, -13.25, 0.25, -31.25, -5.5, -9.5, -21.5, -18.5, 39.25, -2.25, 12.0, -68.5, -21.25, 4.0, -50.75, 26.5, 30.25, -59.0, 63.25, 0.25, 18.5, -43.0, -58.75, 0.25, 10.25, -27.75, 18.75, -7.5, 35.5, 22.5, 4.75, 19.75, -18.75, 50.0, 52.0, -32.0, 37.5, 25.75, 8.0, -29.0, -6.0, -57.25, 42.75, 17.75, 13.25, -59.25, 53.25, -11.25, 20.5, -45.25, 15.25, -93.75, -29.25, -18.75, -16.0, -6.0, 0.5, -11.75, 21.25, -14.5, 10.25, -6.5, 6.25, 47.25, 32.5, -6.0, 11.25, -15.0, 6.0, -7.0, -1.75, 2.75, -52.75, 220.5, 72.0, -104.75, -81.5, -32.0, -36.25, 34.75, -33.5, -17.5, -65.5, -30.0, -17.0, 10.5, -29.0, 5.75, -28.25, 3.0, -41.5, 15.75, -18.75, 5.5, -5.25, -16.5, -9.5, 5.0, -7.0, 35.0, -15.0, -17.25, -38.0, 5.5, -11.25, 12.0, -17.75, -4.25, -16.0, 24.25, -3.25, -0.25, 1.0, -2.5, -7.75, 32.25, 4.25, -2.25, -7.25, 19.0, 4.5, -3.5, -17.75, -26.25, 1.5, 31.75, 125.0, -95.75, 35.5, 0.25, -83.75, -3.75, 20.5, -1.75, -50.0, -37.25, 30.75, 37.0, -47.0, -10.75, 22.5, -31.0, 1.5, 9.25, -17.0, 2.0, 11.25, 65.0, 8.75, 8.75, -8.25, 0.25, -24.75, -6.5, -15.5, 1.0, -55.5, 20.25, 20.25, 45.0, 12.25, -1.5, 45.5, 37.75, 25.5, 13.5, -66.0, -24.75, -13.25, 73.75, 58.5, -73.25, -18.25, -47.0, 20.25, -40.5, -16.75, 27.75, -18.0, 3.25, -14.0, 56.5, 82.5, -3.0, -61.5, -6.0, -53.0, -18.5, -32.5, 31.25, -70.75, 7.75, -6.0, -5.5, -23.0, -16.5, 6.5, 11.5, -8.5, -19.25, 37.5, 5.25, 56.5, -29.5, -27.0, -27.25, -41.5, -17.5, -9.25, -13.75, 9.75, -26.0, 16.0, -14.0, -0.25, -2.75, -4.5, -32.5, -46.5, 0.5, -18.25, 21.75, 10.75, -16.5, 16.75, -25.5, -0.5, -19.75, -16.25, -22.5, -15.5, -30.0, -16.75, -35.5, 12.5, -25.5, -20.25, -5.5, 20.5, -14.0, -7.5, 12.75, -51.5, 18.0, -13.25, 8.0, 5.0, -13.0, -4.5, -12.0, -14.5, 13.0, -34.75, -0.75, -5.5, -11.25, 77.5, -31.5, 11.0, -21.75, -19.0, -22.5, -27.0, -1.5, 2.25, 2.25, -11.25, 30.75, -8.75, 5.5, -1.5, 25.0, 30.0, 10.0, -42.5, 8.25, -8.0, -44.75, 3.0, -33.0, -46.25, 10.5, -55.75, 4.0, -49.75, -10.75, 7.75, -16.75, -21.25, 2.75, -22.0, 3.0, 4.0, -19.0, -11.75, -19.25, 144.75, -55.0, -21.75, -49.25, -10.0, -21.75, -50.5, -11.0, 1.0, -0.75, -17.25, -62.25, -2.5, 17.0, -17.5, -7.25, 132.0, 29.5, -38.0, 27.0, 20.25, -0.5, -71.75, 34.0, -67.75, 7.5, -26.75, 24.75, 104.25, -89.75, 113.25, -4.5, -60.25, 53.75, -57.25, -31.0, -28.0, -66.25, -10.75, -43.75, -11.5, -24.5, -22.75, -5.75, 12.0, -14.75, -8.5, -14.25, 51.5, -1.25, 27.5, -4.75, 22.25, 21.25, -9.0, -34.0, 17.0, -9.25, 132.75, -69.25, -72.75, 1.5, -8.25, 119.75, -9.0, 11.0, -83.25, 30.25, 5.25, 20.25, -25.0, -49.75, -65.25, -54.5, 5.75, 17.25, -11.5, -18.0, 53.0, -53.75, -15.25, -3.0, 35.5, -8.75, 12.5, -7.25, 18.5, 30.75, 8.5, 54.25, -13.75, -51.25, -2.5, -43.25, 3.5, -12.5, -5.0, -60.75, -2.0, -2.0, -3.0, -18.0, 8.75, -26.75, -18.75, -4.0, 3.0, 23.5, -13.25, 44.75, -14.75, 9.0, -19.75, -123.25, -14.75, -28.0, 9.0, -5.75, -38.0, -28.25, -4.5, -31.0, 27.75, 3.5, 0.5, 17.25, 27.25, -76.5, 29.5, -4.0, -63.75, -8.25, 1.0, -7.0, 118.0, -62.5, 7.5, 105.75, -16.25, -24.0, -25.0, -17.75, -54.5, 20.0, -13.5, 5.0, -88.5, -37.25, 34.25, 15.0, -5.5, 6.0, 22.5, 7.25, 6.0, 35.75, -109.75, -71.25, -19.75, -59.75, -20.25, 0.25, 2.5, -50.0, -49.75, 19.25, -61.0, 5.0, -29.25, -100.25, -36.0, 25.25, 2.0, -92.25, 37.5, 50.0, -24.25, 74.5, 198.25, 323.0, -180.75, 82.25, 224.75, -89.75, -97.25, -30.75, -127.5, -135.0, 29.5, -7.25, 27.75, -32.25, -117.25, -81.75, 87.75, 48.75, 118.75, -41.0, -81.75, -27.25, -66.5, -51.5, -126.25, -40.25, 78.5, 6.0, -9.75, 6.5, 128.75, -5.75, 28.5, 191.25, 138.0, -223.75, 214.5, 73.0, -103.25, 163.75, -63.5, -116.5, -18.25, 153.25, -34.0, -133.75, 32.5, -74.5, 28.0, -37.75, -124.5, -24.0, 75.25, 101.5, 38.5, 134.0, -30.0, -151.5, 75.0, 55.0, -86.0, 82.0, -33.75, -108.25, -47.0, -3.5, -74.0, -69.0, -10.5, -15.75, 78.5, -41.75, 29.5, 34.5, 3.25, 4.75, -51.5, -0.5, -5.25, 45.0, -39.25, 1.5, -100.5, -68.5, -31.75, -33.25, 56.5, 8.5, -35.25, -34.5, 9.5, -80.5, 26.0, 0.0, 22.75, -59.5, 77.5, 5.25, 149.25, -39.75, 100.0, -61.75, -11.5, -48.25, -102.75, -114.75, -67.75, -0.75, 9.75, -123.0, -11.0, 74.5, -101.75, 19.75, 32.25, 20.25, -62.5, 4.0, -59.0, -18.5, 128.25, 92.5, -34.75, 16.0, -101.5, -10.0, -39.75, -34.75, 6.75, -12.0, 45.25, 8.5, -37.25, 86.5, -9.0, -5.25, 3.5, -16.25, -59.0, 9.0, -68.75, -69.0, -9.75, -87.75, 23.75, -19.5, 31.25, 110.5, 72.5, 16.25, -27.25, -51.5, 29.5, -81.25, 18.75, 97.75, -61.0, 1.75, -79.25, -7.5, -46.25, -4.25, 7.75, -67.0, 8.25, -3.5, 22.25, -8.5, 136.75, 85.0, 51.5, -8.0, 362.75, -20.75, -131.5, 100.25, -285.5, 26.5, 170.0, 47.5, -69.5, 14.75, 300.0, -48.0, -11.25, 161.75, -96.0, -118.5, -117.75, 7.0, 23.25, -69.25, -207.0, 46.75, 114.5, 191.25, -6.0, 93.5, -135.5, -20.75, 203.0, 136.0, -48.5, -135.75, -73.0, -196.0, -6.25, -47.25, -17.25, 252.0, 10.0, 212.0, -103.0, -22.0, -82.5, 17.0, 152.5, 113.75, 8.5, 107.0, 23.25, 50.25, -383.5, -40.5, 15.75, -21.0, -21.5, 80.75, -265.25, -45.25, -51.25, -58.0, -28.0, 9.75, 54.0, -133.75, 8.25, -50.0, -70.0, 141.5, -13.25, -12.0, -106.75, 82.5, 56.5, -147.0, -70.5, 33.25, -73.75, -70.5, 13.5, 82.5, -14.75, 7.5, -110.0, 1.0, -2.5, -46.25, -4.5, -4.5, 36.25, -57.0, -17.25, 4.25, -12.5, 18.75, -49.5, 31.25, -21.0, 44.75, 81.5, -1.25, -142.5, -30.5, -58.5, 33.5, -24.60009799999989, -22.75, -14.25, -31.5, -134.0, 158.0, 17.0, -13.75, 49.0, -28.5, -50.25, -68.5, -24.0, -65.25, 19.75, -39.25, -15.75, 32.5, -50.75, 26.75, -35.25, 6.25, -28.75, -13.25, -21.0, -19.5, -100.0, -14.25, 56.75, -41.0, 23.5, 5.25, 92.25, 3.5, -126.0, 6.5, 70.75, 16.25, 44.5, -19.25, 219.5, -105.75, -100.0, -76.0, 89.25, 123.0, -55.75, 32.75, 119.75, 1.25, 20.25, 75.5, -40.5, 118.25, 116.25, -170.5, -39.5, -68.5, -153.0, -46.5, 1.25, 44.5, -46.75, 25.0, -53.25, -103.0, -33.25, -77.25, 13.390137000000323, -14.25, 124.25, -17.0, -49.5, -8.5, -8.5, -45.75, 36.25, 54.0, -43.0, -80.75, 5.5, -42.75, -28.5, 40.0, 54.25, -65.5, 107.75, -94.75, -57.25, -94.0, 22.75, -27.75, 16.25, 41.0, 125.75, 25.75, 94.75, 316.5, -166.5, -40.5, -182.25, 39.25, 87.75, -177.75, 257.75, -27.25, -102.5, -110.25, 49.25, -95.25, 44.75, 201.25, -155.5, 28.75, -35.25, -129.75, 13.5, 10.75, -108.5, -133.5, -4.25, 26.25, 19.0, -71.25, -28.25, 30.25, 0.25, -26.25, -3.5, 2.5, 0.020019999999931315, -11.25, 133.75, -82.0, 35.25, 85.75, -35.0, 88.5, 164.75, -107.0, -110.5, -27.5, 114.0, -78.75, -58.0, -75.75, -7.25, -97.5, 11.5, 1.5, 73.0, -74.0, 90.5, -55.25, -5.5, -107.25, -46.75, 54.0, -54.0, 38.25, -66.0, -50.75, 10.75, 0.75, -16.75, -27.25, 7.5, -21.75, 7.25, 3.5, -51.25, -14.75, -6.5, 41.25, -13.0, -0.25, -73.25, -26.5, -52.0, 108.5, 62.5, -36.5, -13.0, -89.25, 45.5, -9.25, -39.25, -57.75, -9.0, -69.0, -0.25, -20.5, -44.5, -56.459961000000476, -15.75, -74.0, 17.75, 49.75, -20.5, -115.0, 85.5, -75.25, 0.25, -103.0, -60.25, 31.75, -109.25, 25.25, 2.0, -71.75, -37.5, 4.25, -16.25, -58.25, 107.5, 122.5, -152.75, 21.0, -105.0, 228.75, -131.5, -256.0, -24.5, -65.5, 57.5, -126.0, -2.25, -89.5, 8.5, -6.0, -1.0, -90.25, 120.5, 159.25, 264.25, 236.75, 18.0, 428.75, -107.0, -442.0, 248.0, -339.0, 240.25, 173.75, 417.5, -437.75, 313.5, 783.5, -815.75, 845.5, -352.25, 160.75, -41.75, -222.97998000000007, -186.5, -549.0, 77.0, -360.5, 314.25, -459.0, 70.5, 333.75, -153.75, 100.25, -494.0, 22.25, -174.75, -32.25, -31.25, -355.5, 112.25, -158.25, 100.75, 107.5, 263.25, -191.0, 37.5, -180.75, -58.25, 99.25, -277.25, 121.0, 129.0, -171.5, -118.0, -23.5, -160.25, -103.25, -84.25, 203.75, 53.5, -66.75, -11.0, -190.5, 15.5, -195.75, 139.0, -45.75, -10.25, -23.5, -23.75, -106.75, -82.0, -57.75, -27.25, 59.25, -165.0, -65.75, -63.75, -127.25, 469.5, -29.0, -263.75, -160.0, -32.75, -0.5, -123.58984000000055, -256.75, -74.5, 172.25, -83.0, 221.5, -188.25, -164.25, -127.75, -97.25, -246.5, 67.75, -136.25, -53.25, -110.25, 248.25, -44.25, 22.75, 181.25, -90.25, -329.75, 101.25, 46.5, 301.75, 106.5, -185.25, 142.5, -116.25, -94.0, 16.0, -111.0, -32.0, -11.25, -167.25, 137.75, 68.25, 193.75, -197.5, -59.75, 46.75, -141.75, -123.75, 82.25, -150.25, -82.0, -55.25, -90.25, -251.75, 31.75, -38.5, -111.25, -202.75, -86.0, 608.0, 196.25, 470.5, -386.75, 199.5, 125.5, -176.5, -185.75, 198.75, 179.5, -62.80956999999944, -69.0, -183.25, 331.5, -88.25, -222.25, -249.75, 50.25, -86.25, -199.75, 333.5, -160.75, 199.25, -249.5, -65.75, -162.75, -375.5, 6.0, 105.5, 76.0, 93.0, 166.5, 36.75, -16.0, 33.75, 5.75, 141.75, -88.5, 425.75, -162.25, 167.0, -28.75, -191.0, -499.0, -246.5, 13.5, 318.75, 245.25, -253.75, 78.5, -76.5, -47.75, 86.25, 75.0, -111.25, 54.25, -11.25, -166.25, -53.75, 9.5, -116.25, 2.0, 9.75, -39.0, -71.0, -63.5, 290.25, -59.25, 23.0, -51.0, -131.25, -65.75, -74.0, -55.80956999999944, 76.5, -11.75, 53.5, -156.5, 4.25, 19.25, -45.5, 203.5, -110.75, 183.5, -269.5, -170.25, 196.25, 20.5, -89.75, 74.5, 106.75, -211.25, -264.25, -107.0, 32.5, -105.5, -25.75, 445.5, -133.5, 244.75, -387.5, -216.5, 111.75, -118.0, -38.0, -59.25, 3.25, 54.5, -67.0, -93.5, 61.75, 58.5, 66.5, 62.25, 360.75, 35.0, -131.25, 473.0, -108.5, -322.25, 257.0, 379.5, 227.0, -228.75, 417.75, -443.0, 62.75, -253.0, 121.5, -128.5, -66.75, -26.75, 405.0, 9.490229999999428, -264.75, 62.75, 256.25, 32.5, -167.0, 31.25, 96.75, -195.0, -221.5, -246.5, 33.75, -24.25, -127.0, -43.0, 9.0, -150.75, 179.0, -187.0, -27.5, 91.75, 105.75, -179.25, 146.25, -170.0, -91.75, 71.75, 63.25, 20.0, 98.25, 90.25, 249.0, 34.75, -113.75, -95.25, 361.25, -29.5, 322.75, -131.5, -292.0, 76.75, 96.5, -51.5, -266.0, 87.5, -252.0, 0.25, -30.0, 37.0, 8.25, 50.25, -20.5, 150.25, -235.0, -31.0, 11.5, -1.25, -142.75, -18.75, -125.75, 89.25, 65.5, -217.0, 76.32030999999915, -107.25, -121.5, 11.0, -79.0, 26.75, -162.5, -58.5, 35.75, 10.0, -170.0, -71.25, -37.75, 99.75, -100.25, -45.25, 15.0, -22.0, 107.5, 108.0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class ShowerEnv(Env):\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    def get_y(self, time):\r\n",
    "\r\n",
    "        y_out = encoded_Y[time]\r\n",
    "\r\n",
    "        return y_out     \r\n",
    "\r\n",
    "    def __init__(self):\r\n",
    "\r\n",
    "        \r\n",
    "\r\n",
    "        self.time = 0\r\n",
    "\r\n",
    "        \r\n",
    "        self.cash = 3000\r\n",
    "        \r\n",
    "        \r\n",
    "        self.action_space = Discrete(2)\r\n",
    "\r\n",
    "        self.state = np.reshape(tot_train[self.time], -1)\r\n",
    "        print(self.state)\r\n",
    "        self.shape = (10,)\r\n",
    "\r\n",
    "\r\n",
    "        \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    def step(self, action):\r\n",
    "        self.time +=1\r\n",
    "        self.state = tot_train[self.time]\r\n",
    "\r\n",
    "        y = self.get_y(self.time)\r\n",
    "        #print(action, y)\r\n",
    "        if( y == action):\r\n",
    "            reward = abs(dif[self.time])\r\n",
    "            self.cash += reward\r\n",
    "        else:\r\n",
    "            reward = -abs(dif[self.time-1])\r\n",
    "            self.cash += reward\r\n",
    "\r\n",
    "        if self.time >= 1000:\r\n",
    "            done = True\r\n",
    "        else:\r\n",
    "            done = False\r\n",
    "\r\n",
    "        info = {}\r\n",
    "        #print (self.cash)\r\n",
    "        return self.state, reward, done, info\r\n",
    "        \r\n",
    "\r\n",
    "    def render(self):\r\n",
    "        pass\r\n",
    "    def reset(self):\r\n",
    "        self.time = 0\r\n",
    "        self.cash = 3000\r\n",
    "        self.state = tot_train[self.time]\r\n",
    "        return self.state\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "env = ShowerEnv()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.58857833 -0.05885783  0.         -0.79725611 -0.12039102 -0.68283699\n",
      " -0.06828287  0.         -0.72737274]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "env.action_space.sample()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "episodes = 2\r\n",
    "for episode in range(1, episodes+1):\r\n",
    "    state = env.reset()\r\n",
    "    done = False\r\n",
    "    score = 0\r\n",
    "    \r\n",
    "    while not done:\r\n",
    "        env.render()\r\n",
    "        action = env.action_space.sample()\r\n",
    "        n_state, reward, done, info = env.step(action)\r\n",
    "        score += reward\r\n",
    "    print('Episode:{} score:{}'.format(episode, score))\r\n",
    "env.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode:1 score:2094.129882\n",
      "Episode:2 score:1151.7099609999996\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "states= (9,)\r\n",
    "actions = env.action_space.n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def build_model(states, actions):\r\n",
    "    model = Sequential()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    model.add(Flatten(input_shape = (2,9)))\r\n",
    "    model.add(Dense(32, activation=\"relu\"))\r\n",
    "    model.add(Dense(128, activation=\"relu\"))\r\n",
    "    model.add(Dense(128, activation=\"relu\"))\r\n",
    "    model.add(Dense(32, activation=\"relu\"))\r\n",
    "    model.add(Dense(actions, activation = 'softmax'))\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = build_model(states, actions)\r\n",
    "model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                608       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 25,538\n",
      "Trainable params: 25,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def build_agent(model, actions):\r\n",
    "    policy = BoltzmannQPolicy()\r\n",
    "    \r\n",
    "    memory = SequentialMemory(limit =100, window_length =2)\r\n",
    "    \r\n",
    "    dqn = DQNAgent(model = model,\r\n",
    "                   memory=memory,\r\n",
    "                   policy=policy, \r\n",
    "                   \r\n",
    "                   nb_actions = actions,\r\n",
    "                   nb_steps_warmup =1000,\r\n",
    "                   target_model_update=1e-2\r\n",
    "                  )\r\n",
    "    return dqn\r\n",
    "\r\n",
    "    \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dqn = build_agent(model, actions)\r\n",
    "dqn.compile(Adam(lr=1e-4), metrics=['mae'])\r\n",
    "dqn.fit(env, nb_steps = 100000, visualize=False, verbose =1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From C:\\Users\\bartw\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " 2758/10000 [=======>......................] - ETA: 30s - reward: 3.6370done, took 11.463 seconds\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c5b1930c8>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores = dqn.test(env, nb_episodes=1, visualize=False)\r\n",
    "print(np.mean(scores.history['episode_reward']))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('games_rl': conda)"
  },
  "interpreter": {
   "hash": "e99ec45d6c852ea5fa3d4ad7a082220a83a169bae09a9553fb02d3b9b2eecb83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}